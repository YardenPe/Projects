{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da83d9da-9e9e-4703-9932-0abf086d54f7",
   "metadata": {},
   "source": [
    "1. https://www.geeksforgeeks.org/different-techniques-for-sentence-semantic-similarity-in-nlp/\n",
    "2. Course website with code: http://spacy.pythonhumanities.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "6f722a72-15cf-40d6-bc29-a636da31ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e4f5a0e0-6720-4a12-b45d-97faa3abc3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America. It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j] At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d] The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22] With a population of more than 331 million people, it is the third most populous country in the world. The national capital is Washington, D.C., and the most populous city is New York.\n",
      "\n",
      "Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago, and European colonization began in the 16th century. The United States emerged from the thirteen British colonies established along the East Coast. Disputes over taxation and political representation with Great Britain led to the American Revolutionary War (1775â€“1783), which established independence. In the late 18th century, the U.S. began expanding across North America, gradually obtaining new territories, sometimes through war, frequently displacing Native Americans, and admitting new states; by 1848, the United States spanned the continent. Slavery was legal in the southern United States until the second half of the 19th century when the American Civil War led to its abolition. The Spanishâ€“American War and World War I established the U.S. as a world power, a status confirmed by the outcome of World War II.\n",
      "\n",
      "During the Cold War, the United States fought the Korean War and the Vietnam War but avoided direct military conflict with the Soviet Union. The two superpowers competed in the Space Race, culminating in the 1969 spaceflight that first landed humans on the Moon. The Soviet Union's dissolution in 1991 ended the Cold War, leaving the United States as the world's sole superpower.\n",
      "\n",
      "The United States is a federal republic and a representative democracy with three separate branches of government, including a bicameral legislature. It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States, NATO, and other international organizations. It is a permanent member of the United Nations Security Council. Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by centuries of immigration. The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption. However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.\n",
      "\n",
      "The United States is a highly developed country, accounts for approximately a quarter of global GDP, and is the world's largest economy. By value, the United States is the world's largest importer and the second-largest exporter of goods. Although its population is only 4.2% of the world's total, it holds 29.4% of the total wealth in the world, the largest share held by any country. Making up more than a third of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]\n"
     ]
    }
   ],
   "source": [
    "with open(\"wiki_us.txt\", \"r\") as f:\n",
    "    text= f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b2cc015e-641e-4f79-97de-f11b0f06f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3525\n",
      "652\n"
     ]
    }
   ],
   "source": [
    "#create a doc object - split text to tokens\n",
    "doc= nlp(text)\n",
    "print(len(text))\n",
    "print(len(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "296629a4-d707-44fa-b3a6-5472936622cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "U\n",
      "n\n",
      "i\n",
      "t\n",
      "e\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for token in text[:10]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f5b5889c-4c9f-4913-85d2-dcded93bc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "United\n",
      "States\n",
      "of\n",
      "America\n",
      "(\n",
      "U.S.A.\n",
      "or\n",
      "USA\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for token in doc[:10]:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7e847671-da5e-446a-a29b-2505217253f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "United\n",
      "States\n",
      "of\n",
      "America\n",
      "(U.S.A.\n",
      "or\n",
      "USA),\n",
      "commonly\n",
      "known\n"
     ]
    }
   ],
   "source": [
    "#Example why split is not good:\n",
    "for token in text.split()[:10]:\n",
    "    print(token)\n",
    "#USA),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "78dd9e31-c06b-450e-8e0a-2b68675a3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n",
      "It consists of 50 states, a federal district, five major unincorporated territories, 326 Indian reservations, and some minor possessions.[j]\n",
      "At 3.8 million square miles (9.8 million square kilometers), it is the world's third- or fourth-largest country by total area.[d]\n",
      "The United States shares significant land borders with Canada to the north and Mexico to the south, as well as limited maritime borders with the Bahamas, Cuba, and Russia.[22]\n",
      "With a population of more than 331 million people, it is the third most populous country in the world.\n",
      "The national capital is Washington, D.C., and the most populous city is New York.\n",
      "\n",
      "\n",
      "Paleo-Indians migrated from Siberia to the North American mainland at least 12,000 years ago, and European colonization began in the 16th century.\n",
      "The United States emerged from the thirteen British colonies established along the East Coast.\n",
      "Disputes over taxation and political representation with Great Britain led to the American Revolutionary War (1775â€“1783), which established independence.\n",
      "In the late 18th century, the U.S. began expanding across North America, gradually obtaining new territories, sometimes through war, frequently displacing Native Americans, and admitting new states; by 1848, the United States spanned the continent.\n",
      "Slavery was legal in the southern United States until the second half of the 19th century when the American Civil War led to its abolition.\n",
      "The Spanishâ€“American War and World War I established the U.S. as a world power, a status confirmed by the outcome of World War II.\n",
      "\n",
      "\n",
      "During the Cold War, the United States fought the Korean War and the Vietnam War but avoided direct military conflict with the Soviet Union.\n",
      "The two superpowers competed in the Space Race, culminating in the 1969 spaceflight that first landed humans on the Moon.\n",
      "The Soviet Union's dissolution in 1991 ended the Cold War, leaving the United States as the world's sole superpower.\n",
      "\n",
      "\n",
      "The United States is a federal republic and a representative democracy with three separate branches of government, including a bicameral legislature.\n",
      "It is a founding member of the United Nations, World Bank, International Monetary Fund, Organization of American States, NATO, and other international organizations.\n",
      "It is a permanent member of the United Nations Security Council.\n",
      "Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by centuries of immigration.\n",
      "The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption.\n",
      "However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.\n",
      "\n",
      "\n",
      "The United States is a highly developed country, accounts for approximately a quarter of global GDP, and is the world's largest economy.\n",
      "By value, the United States is the world's largest importer and the second-largest exporter of goods.\n",
      "Although its population is only 4.2% of the world's total, it holds 29.4% of the total wealth in the world, the largest share held by any country.\n",
      "Making up more than a third of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]\n"
     ]
    }
   ],
   "source": [
    "#sentnce boundary detection\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3869cb44-544b-49f0-81a0-e6742b0be380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
     ]
    }
   ],
   "source": [
    "#doc.sents[0] is a generator so need to be converted into a list\n",
    "sentence1= list(doc.sents)[0]\n",
    "print(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f912b73b-8dcb-4a07-9252-ad3793fb3a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "States"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2= sentence1[2]\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a4edf1d1-bbc2-4c8b-a8f0-6b8edaafe841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'States'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a957bd7a-375b-4a65-a2ac-226cf19ef10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "America\n"
     ]
    }
   ],
   "source": [
    "#it's telling us it's a part of a multy word token (multiple components)\n",
    "print(token2.left_edge)\n",
    "print(token2.right_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ca73b7ad-77b6-44fb-9c45-d09aec8f2a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPE'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Type of entity = Geo political entity\n",
    "token2.ent_type_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9721548d-9114-4ab7-af0a-1bf6faa31e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iob = named entity code,shortcut: inside and outside of an entity, begging of entity\n",
    "token2.ent_iob_\n",
    "\n",
    "# I --> shows us the word states is inside of an entity (The united states of america)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "923489a5-1e83-48ff-932f-e89ed83e1fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'States'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2.lemma_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c0d422dd-2944-4b77-aa6f-d0a043a5e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "known\n",
      "know\n"
     ]
    }
   ],
   "source": [
    "#strip the word to the core basis\n",
    "print(sentence1[12])\n",
    "print(sentence1[12].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8a35c12a-6393-4f60-8a96-462517c50223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number=Sing\n",
      "Aspect=Perf|Tense=Past|VerbForm=Part\n"
     ]
    }
   ],
   "source": [
    "#extract information from text - kind of noun\n",
    "print(token2.morph)\n",
    "print(sentence1[12].morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5316d734-85eb-481c-a6bf-d36951ce59a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "nsubj\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "#part of speech\n",
    "print(token2.pos_)\n",
    "#proper noun\n",
    "\n",
    "#dependency decision - role in the sentence\n",
    "print(token2.dep_)\n",
    "\n",
    "#language of the doc object - here it's english\n",
    "print(token2.lang_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b550f-d2f8-43d4-8360-46c1d8e2474d",
   "metadata": {},
   "source": [
    "### Part of speech tagging (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d29a7fc4-9eaa-459c-a59c-d48220c5faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike PROPN nsubj\n",
      "enjoys VERB ROOT\n",
      "playing VERB xcomp\n",
      "football NOUN dobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "text= 'Mike enjoys playing football.'\n",
    "doc2= nlp(text)\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "434e009a-3976-43ed-9c16-786504f0c79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4a34442cab9d49b99dbfc452bf9937ff-0\" class=\"displacy\" width=\"750\" height=\"224.5\" direction=\"ltr\" style=\"max-width: none; height: 224.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mike</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">enjoys</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">playing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"134.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">football.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4a34442cab9d49b99dbfc452bf9937ff-0-0\" stroke-width=\"2px\" d=\"M70,89.5 C70,2.0 225.0,2.0 225.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4a34442cab9d49b99dbfc452bf9937ff-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,91.5 L62,79.5 78,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4a34442cab9d49b99dbfc452bf9937ff-0-1\" stroke-width=\"2px\" d=\"M245,89.5 C245,2.0 400.0,2.0 400.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4a34442cab9d49b99dbfc452bf9937ff-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,91.5 L408.0,79.5 392.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4a34442cab9d49b99dbfc452bf9937ff-0-2\" stroke-width=\"2px\" d=\"M420,89.5 C420,2.0 575.0,2.0 575.0,89.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4a34442cab9d49b99dbfc452bf9937ff-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,91.5 L583.0,79.5 567.0,79.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#see how the sentence is structured\n",
    "from spacy import displacy\n",
    "displacy.render(doc2, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad57525-b891-456b-bd3e-8cb72fa3655e",
   "metadata": {},
   "source": [
    "### Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "248e02b9-2343-4830-8389-cbdba3198025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America GPE\n",
      "U.S.A. GPE\n",
      "USA GPE\n",
      "the United States GPE\n",
      "U.S. GPE\n",
      "US GPE\n",
      "America GPE\n",
      "North America LOC\n",
      "50 CARDINAL\n",
      "five CARDINAL\n",
      "326 CARDINAL\n",
      "Indian NORP\n",
      "3.8 million square miles QUANTITY\n",
      "9.8 million square kilometers QUANTITY\n",
      "fourth ORDINAL\n",
      "The United States GPE\n",
      "Canada GPE\n",
      "Mexico GPE\n",
      "Bahamas GPE\n",
      "Cuba GPE\n",
      "more than 331 million CARDINAL\n",
      "third ORDINAL\n",
      "Washington GPE\n",
      "D.C. GPE\n",
      "New York GPE\n",
      "Paleo-Indians NORP\n",
      "Siberia LOC\n",
      "North American NORP\n",
      "at least 12,000 years ago DATE\n",
      "European NORP\n",
      "the 16th century DATE\n",
      "The United States GPE\n",
      "thirteen CARDINAL\n",
      "British NORP\n",
      "the East Coast LOC\n",
      "Great Britain GPE\n",
      "the American Revolutionary War ORG\n",
      "the late 18th century DATE\n",
      "U.S. GPE\n",
      "North America LOC\n",
      "Native Americans NORP\n",
      "1848 DATE\n",
      "the United States GPE\n",
      "United States GPE\n",
      "the second half of the 19th century DATE\n",
      "the American Civil War ORG\n",
      "The Spanishâ€“American War and World War EVENT\n",
      "U.S. GPE\n",
      "World War II EVENT\n",
      "the Cold War EVENT\n",
      "the United States GPE\n",
      "the Korean War EVENT\n",
      "the Vietnam War EVENT\n",
      "the Soviet Union GPE\n",
      "two CARDINAL\n",
      "the Space Race FAC\n",
      "1969 DATE\n",
      "first ORDINAL\n",
      "The Soviet Union's GPE\n",
      "1991 DATE\n",
      "the Cold War EVENT\n",
      "the United States GPE\n",
      "The United States GPE\n",
      "three CARDINAL\n",
      "the United Nations ORG\n",
      "World Bank ORG\n",
      "International Monetary Fund ORG\n",
      "Organization of American States ORG\n",
      "NATO ORG\n",
      "the United Nations Security Council ORG\n",
      "centuries DATE\n",
      "The United States GPE\n",
      "approximately a quarter DATE\n",
      "the United States GPE\n",
      "second ORDINAL\n",
      "only 4.2% PERCENT\n",
      "29.4% PERCENT\n",
      "more than a third CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0842cf-8f33-4843-a043-55da6ce01e79",
   "metadata": {},
   "source": [
    "Examples:\n",
    "gpe= geopolitical entity,\n",
    "loc=  location,\n",
    "cardinal= number,\n",
    "norp= national or religious entity,\n",
    "ORG= organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "aea4178f-39bb-4619-92da-ab06213476a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The United States of America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.A.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    USA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "), commonly known as \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ") or \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", is a country primarily located in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    North America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". It consists of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    50\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " states, a federal district, \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    five\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " major unincorporated territories, \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    326\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Indian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " reservations, and some minor possessions.[j] At \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3.8 million square miles\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    9.8 million square kilometers\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       "), it is the world's third- or \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fourth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       "-largest country by total area.[d] \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " shares significant land borders with \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canada\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to the north and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mexico\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to the south, as well as limited maritime borders with the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bahamas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cuba\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and Russia.[22] With a population of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than 331 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " people, it is the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " most populous country in the world. The national capital is \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Washington\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    D.C.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", and the most populous city is \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".<br><br>\n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paleo-Indians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " migrated from \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Siberia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " to the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    North American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " mainland \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    at least 12,000 years ago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " colonization began in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the 16th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " emerged from the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thirteen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    British\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " colonies established along \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the East Coast\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Disputes over taxation and political representation with \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Great Britain\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " led to \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the American Revolutionary War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (1775â€“1783), which established independence. In \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the late 18th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " began expanding across \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    North America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", gradually obtaining new territories, sometimes through war, frequently displacing \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Native Americans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       ", and admitting new states; by \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1848\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " spanned the continent. Slavery was legal in the southern \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the second half of the 19th century\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " when \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the American Civil War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " led to its abolition. \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Spanishâ€“American War and World War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " I established the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " as a world power, a status confirmed by the outcome of \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World War II\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       ".<br><br>During \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Cold War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " fought \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Korean War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Vietnam War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " but avoided direct military conflict with \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Soviet Union\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". The \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " superpowers competed in \n",
       "<mark class=\"entity\" style=\"background: #9cc9cc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Space Race\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ", culminating in the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1969\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " spaceflight that \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    first\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " landed humans on the Moon. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The Soviet Union's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " dissolution in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1991\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " ended \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Cold War\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       ", leaving \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " as the world's sole superpower.<br><br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a federal republic and a representative democracy with \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " separate branches of government, including a bicameral legislature. It is a founding member of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United Nations\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Bank\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    International Monetary Fund\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Organization of American States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NATO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and other international organizations. It is a permanent member of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United Nations Security Council\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". Considered a melting pot of cultures and ethnicities, its population has been profoundly shaped by \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    centuries\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of immigration. The country ranks high in international measures of economic freedom, quality of life, education, and human rights, and has low levels of perceived corruption. However, the country has received criticism concerning inequality related to race, wealth and income, the use of capital punishment, high incarceration rates, and lack of universal health care.<br><br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a highly developed country, accounts for \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    approximately a quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of global GDP, and is the world's largest economy. By value, \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is the world's largest importer and the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       "-largest exporter of goods. Although its population is \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 4.2%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of the world's total, it holds \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    29.4%\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERCENT</span>\n",
       "</mark>\n",
       " of the total wealth in the world, the largest share held by any country. Making up \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    more than a third\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of global military spending, it is the foremost military power in the world; and it is a leading political, cultural, and scientific force internationally.[23]</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0f4986-c8f8-418a-adf2-6ebf3e93240d",
   "metadata": {},
   "source": [
    "### word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "95e35457-9135-4cda-a980-b294fd1c387a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.59222260e-01, -4.17643905e-01, -6.36026502e-01,  1.97980964e+00,\n",
       "       -9.92742717e-01,  3.27986181e-01, -1.43436813e+00,  3.92762125e-01,\n",
       "       -2.21372217e-01,  1.23972368e+00,  1.46654427e+00,  9.07576144e-01,\n",
       "       -3.52612495e-01, -7.64090002e-01, -9.86878872e-01, -9.11739588e-01,\n",
       "       -6.99107826e-01,  1.38432574e+00, -1.03957617e+00, -2.26922899e-01,\n",
       "       -1.09980154e+00, -2.52399504e-01,  2.09237009e-01, -1.43642986e+00,\n",
       "        1.98636830e+00,  4.54234242e-01,  8.36412311e-01,  1.15134805e-01,\n",
       "        5.11804223e-03,  8.08914304e-01,  4.18873399e-01, -1.57853103e+00,\n",
       "        6.36767626e-01, -9.50180352e-01,  5.02419174e-01,  1.34429443e+00,\n",
       "        8.22311565e-02, -1.14306271e-01,  1.54729724e-01,  2.90426373e+00,\n",
       "       -3.52550358e-01,  7.49375045e-01, -1.52755511e+00,  4.65825021e-01,\n",
       "       -1.63595057e+00,  7.50666797e-01,  5.89215100e-01,  1.65174007e+00,\n",
       "        7.01108217e-01,  2.49644145e-01, -9.34628427e-01, -4.80721891e-01,\n",
       "        3.71875763e-01,  5.87381721e-01, -2.66013801e-01,  5.64918399e-01,\n",
       "       -7.59065747e-01,  1.70134115e+00,  3.32356215e-01, -7.89472461e-02,\n",
       "       -4.40568388e-01,  8.82627010e-01,  7.41947830e-01, -3.90778840e-01,\n",
       "        6.57645822e-01, -7.68142223e-01, -2.48638153e-01, -1.02533710e+00,\n",
       "       -1.50129151e+00, -1.33207512e+00, -3.68103266e-01,  1.71081305e+00,\n",
       "       -1.14189446e-01,  1.69506788e-01, -9.31923330e-01, -8.19137156e-01,\n",
       "       -4.44367945e-01, -7.39296138e-01,  1.68365732e-01,  4.65136588e-01,\n",
       "       -4.09116328e-01, -1.20210505e+00, -3.78459960e-01, -1.41465378e+00,\n",
       "        1.88349271e+00,  1.26072660e-01,  7.10422635e-01, -2.39819348e-01,\n",
       "        2.27352798e-01, -1.76141471e-01, -2.47895718e-01, -3.68946254e-01,\n",
       "       -4.32029366e-04, -3.08454156e-01, -4.14541185e-01,  7.27797270e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0bf7e122-a918-438f-ad4d-4c9990a6a2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "64a07588-9b90-4998-a96f-60cc201c4e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America."
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"wiki_us.txt\", \"r\") as f:\n",
    "    text= f.read()\n",
    "doc= nlp(text)\n",
    "sentence1= list(doc.sents)[0]\n",
    "sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe30b6f0-1eb1-4200-af23-8f089136b9fe",
   "metadata": {},
   "source": [
    "### This way does not work for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b4baa6cc-ef98-424d-bc1a-e745d68e15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country—0,467', 'nationâ\\x80\\x99s', 'countries-', 'continente', 'Carnations', 'pastille', 'бесплатно', 'Argents', 'Tywysogion', 'Teeters']\n"
     ]
    }
   ],
   "source": [
    "#how the word country is similar to other words- shows all the words that are most similar to the word country\n",
    "your_word = \"country\"\n",
    "ms = nlp.vocab.vectors.most_similar(\n",
    "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]]), n=10)\n",
    "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "distances = ms[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "3c58e87b-c2ba-437c-beec-d6051caa0440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.691649353055761\n",
      "I like salty fries and hamburgers. <-> The empire state building is in New York. 0.28381538599604816\n",
      "I enjoy oranges. <-> I enjoy Appels. 0.9734628736186025\n"
     ]
    }
   ],
   "source": [
    "# make calculatings to how similar this two sentences\\words are\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "doc3 = nlp(\"The empire state building is in New York.\")\n",
    "doc4 = nlp(\"I enjoy oranges.\")\n",
    "doc5 = nlp(\"I enjoy Appels.\")\n",
    "\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "print(doc1, \"<->\", doc3, doc1.similarity(doc3))\n",
    "print(doc4, \"<->\", doc5, doc4.similarity(doc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2bf23-c039-424d-a7f6-5dbb3688dd84",
   "metadata": {},
   "source": [
    "fries and hamburgers are in fast food so they are more similar.\n",
    "\n",
    "Same for fruits afterwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ccbf6-3048-4fab-8975-97490aae86f8",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a614af41-481f-4420-855e-2aacfeebe2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x21618942950>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8a46358d-1f78-4fad-9b03-b731c9776e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate quantity of sentences in it\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#download the text of Shakespeare's works\n",
    "s = requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\n",
    "#remove hyphenated line breaks and replace newlines with spaces, set maximum length to process the text\n",
    "soup = BeautifulSoup(s.content).text.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
    "nlp.max_length = 5278439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "20182c29-993a-436c-a760-ae3002c91ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94134\n"
     ]
    }
   ],
   "source": [
    "#quantity of sentences\n",
    "doc = nlp(soup)\n",
    "print(len(list(doc.sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "3da01a47-05f0-4841-9c88-0e06ac6b0f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'sentencizer': {'assigns': ['token.is_sent_start', 'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['sents_f', 'sents_p', 'sents_r'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'sentencizer': []},\n",
       " 'attrs': {'doc.sents': {'assigns': ['sentencizer'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['sentencizer'], 'requires': []}}}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0c2c64aa-7420-4f77-8594-d756b92492b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': []},\n",
       " 'attrs': {'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []}}}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2.analyze_pipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d87a257-7ee0-4843-9ec5-43ccf0dfd061",
   "metadata": {},
   "source": [
    "### Entity Ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "03456aa8-cd1e-413f-a2e7-be63d0d5fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d3daada9-adb7-453c-b5e3-0b7dfab1aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"West Chestertenfieldville was referenced in Mr. Deedes.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b9268f07-fd91-42a8-bad8-a8a850462c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Chestertenfieldville GPE\n",
      "Deedes PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03042bd-6623-4126-8f69-5befc51a5c85",
   "metadata": {},
   "source": [
    "making the best prediction it can but model doesn't get it right all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "03140673-ba8f-48b9-822b-dcf14dec0838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "1f338137-7516-4419-8764-7455a76c050f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': [],\n",
       "  'entity_ruler': []},\n",
       " 'attrs': {'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner', 'entity_ruler'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner', 'entity_ruler'], 'requires': []}}}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that it was added to our pipeline\n",
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "1717431b-612e-4aba-91d3-139bfc722ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "491b76a4-6c1f-45d9-934b-2c2f6859382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##entity ruler should come before ner in the pipeline - place it before ner.\n",
    "ruler = nlp2.add_pipe(\"entity_ruler\", before='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7c7d5e24-b21a-40fd-b22e-39744bd6d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want it to recognize it as GPE if it doesn't\n",
    "patterns = [\n",
    "    {\"label\":\"GPE\", \"pattern\":\"West Chestertenfieldville\"},\n",
    "    {\"label\":\"FILM\", \"pattern\":\"Mr. Deedes\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "ddea850c-aa3f-4545-80bb-98a73a55d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the pattern to the ruler\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4e72d75f-300e-46b7-9f05-b85925c1fc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Chestertenfieldville GPE\n",
      "Mr. Deedes FILM\n"
     ]
    }
   ],
   "source": [
    "doc= nlp2(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "97f640c6-5618-4be1-9fa7-f776032144ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'entity_ruler': {'assigns': ['doc.ents', 'token.ent_type', 'token.ent_iob'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'entity_ruler': [],\n",
       "  'ner': []},\n",
       " 'attrs': {'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['entity_ruler', 'ner'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['entity_ruler', 'ner'], 'requires': []}}}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see entity ruler before ner\n",
    "nlp2.analyze_pipes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8732fe-675f-4591-af88-fdeb7c3b0d46",
   "metadata": {},
   "source": [
    "toponym = a problem when a maching learining model fails to recognize Mr. Deeds as a film or as a person depending on the context.\n",
    "\n",
    "toponym resolution= Multiple labels that are dependent on context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93fbef1-8d1a-46ec-a210-4dc62726bf3b",
   "metadata": {},
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023883c-09eb-473d-ba7f-801ae5613c78",
   "metadata": {},
   "source": [
    "structure that helps extract information and not exactly entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e86feac1-7c7e-43a3-bfb4-7accf36757f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f24b49fe-8bfe-4d55-aa2b-d218acde021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "851cd58b-0a64-4124-aa7e-9e83c8a5f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LIKE_EMAIL\":True}]\n",
    "# argument1 - add to nlp vocab as a lexeme, argument2- each one of this pattern will be a list of lists.\n",
    "matcher.add(\"EMAIL_ADDRESS\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f8c4e897-faf4-47ac-bb8e-67d4fb1a0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(\"This is my email address: wmattingly@aol.com\")\n",
    "matches= matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "fba0a653-500d-4627-87c0-c161bed1171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16571425990740197027, 6, 7)]\n"
     ]
    }
   ],
   "source": [
    "# list which is a set of tuples. 1=lexeme, start token and ent token.\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "a0476a80-c68a-439b-9d30-682e89f0004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMAIL_ADDRESS\n"
     ]
    }
   ],
   "source": [
    "#label was added to vocab\n",
    "print(nlp.vocab[matches[0][0]].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639b6d7-1c4f-4bea-945a-c463e8b024e4",
   "metadata": {},
   "source": [
    "Attributes Taken by Matcher: https://spacy.io/api/matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c6bab-212a-4461-96d9-72d1dbfa446e",
   "metadata": {},
   "source": [
    "OP = operator or quantifier that defines how often to match a token - in the google docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dbcea16e-f27c-45b9-bfb0-04071e8a7037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Martin Luther King Jr. (born Michael King Jr.; January 15, 1929 â€“ April 4, 1968) was an American Baptist minister and activist who became the most visible spokesman and leader in the American civil rights movement from 1955 until his assassination in 1968. King advanced civil rights through nonviolence and civil disobedience, inspired by his Christian beliefs and the nonviolent activism of Mahatma Gandhi. He was the son of early civil rights activist and minister Martin Luther King Sr.\n",
      "\n",
      "King participated in and led marches for blacks' right to vote, desegregation, labor rights, and other basic civil rights.[1] King led the 1955 Montgomery bus boycott and later became the first president of the Southern Christian Leadership Conference (SCLC). As president of the SCLC, he led the unsuccessful Albany Movement in Albany, Georgia, and helped organize some of the nonviolent 1963 protests in Birmingham, Alabama. King helped organize the 1963 March on Washington, where he delivered his famous \"I Have a Dream\" speech on the steps of the Lincoln Memorial.\n",
      "\n",
      "The SCLC put into practice the tactics of nonviolent protest with some success by strategically choosing the methods and places in which protests were carried out. There were several dramatic stand-offs with segregationist authorities, who sometimes turned violent.[2] Federal Bureau of Investigation (FBI) Director J. Edgar Hoover considered King a radical and made him an object of the FBI's COINTELPRO from 1963, forward. FBI agents investigated him for possible communist ties, recorded his extramarital affairs and reported on them to government officials, and, in 1964, mailed King a threatening anonymous letter, which he interpreted as an attempt to make him commit suicide.[3]\n",
      "\n",
      "On October 14, 1964, King won the Nobel Peace Prize for combating racial inequality through nonviolent resistance. In 1965, he helped organize two of the three Selma to Montgomery marches. In his final years, he expanded his focus to include opposition towards poverty, capitalism, and the Vietnam War.\n",
      "\n",
      "In 1968, King was planning a national occupation of Washington, D.C., to be called the Poor People's Campaign, when he was assassinated on April 4 in Memphis, Tennessee. His death was followed by riots in many U.S. cities. Allegations that James Earl Ray, the man convicted of killing King, had been framed or acted in concert with government agents persisted for decades after the shooting. King was posthumously awarded the Presidential Medal of Freedom in 1977 and the Congressional Gold Medal in 2003. Martin Luther King Jr. Day was established as a holiday in cities and states throughout the United States beginning in 1971; the holiday was enacted at the federal level by legislation signed by President Ronald Reagan in 1986. Hundreds of streets in the U.S. have been renamed in his honor, and the most populous county in Washington State was rededicated for him. The Martin Luther King Jr. Memorial on the National Mall in Washington, D.C., was dedicated in 2011.\n"
     ]
    }
   ],
   "source": [
    "with open(\"wiki_mlk.txt\",\"r\") as f:\n",
    "    text= f.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "21cdd615-5362-485e-a449-da3c2d700e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "(451313080118390996, 0, 1) Martin\n",
      "(451313080118390996, 1, 2) Luther\n",
      "(451313080118390996, 2, 3) King\n",
      "(451313080118390996, 3, 4) Jr.\n",
      "(451313080118390996, 6, 7) Michael\n",
      "(451313080118390996, 7, 8) King\n",
      "(451313080118390996, 8, 9) Jr.\n",
      "(451313080118390996, 10, 11) January\n",
      "(451313080118390996, 16, 17) April\n",
      "(451313080118390996, 24, 25) Baptist\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#all part of speech occurences of proper noun\n",
    "pattern = [{\"POS\":\"PROPN\"}]\n",
    "matcher.add(\"PROPER_NOUN\", [pattern])\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "# how many matches were found\n",
    "print(len(matches))\n",
    "#match[1]-start token, match[2]-end token\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecc321-6489-43cb-8e1c-76d8f658753b",
   "metadata": {},
   "source": [
    "We have a problem with it\n",
    "\n",
    "OP  + --> look for proper noun that occurs one or more times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "eba157a4-d7ee-4274-adc2-9a651db2127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(451313080118390996, 84, 89) Martin Luther King Sr.\n",
      "(451313080118390996, 470, 475) Martin Luther King Jr. Day\n",
      "(451313080118390996, 537, 542) Martin Luther King Jr. Memorial\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 129, 133) Southern Christian Leadership Conference\n",
      "(451313080118390996, 248, 252) Director J. Edgar Hoover\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 326, 329) Nobel Peace Prize\n",
      "(451313080118390996, 423, 426) James Earl Ray\n",
      "(451313080118390996, 464, 467) Congressional Gold Medal\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#all part of speech occurences of proper noun, + is one or more times\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"}]\n",
    "# only looks for longest token to give back\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "# how many matches were found\n",
    "print(len(matches))\n",
    "#match[1]-start token, match[2]-end token\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19038c3-8444-425f-8f91-d6b42b954c51",
   "metadata": {},
   "source": [
    "It's out of order- greedy longets make them organized from longest to shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "1f284929-1566-436a-af20-7bceb70673e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "(451313080118390996, 0, 4) Martin Luther King Jr.\n",
      "(451313080118390996, 6, 9) Michael King Jr.\n",
      "(451313080118390996, 10, 11) January\n",
      "(451313080118390996, 16, 17) April\n",
      "(451313080118390996, 24, 25) Baptist\n",
      "(451313080118390996, 50, 51) King\n",
      "(451313080118390996, 70, 72) Mahatma Gandhi\n",
      "(451313080118390996, 84, 89) Martin Luther King Sr.\n",
      "(451313080118390996, 90, 91) King\n",
      "(451313080118390996, 114, 115) King\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#all part of speech occurences of proper noun, + is one or more times\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"}]\n",
    "# only looks for longest token to give back\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "#sort our matches - sort it by first index (start token)\n",
    "matches.sort(key= lambda x: x[1])\n",
    "# how many matches were found\n",
    "print(len(matches))\n",
    "#match[1]-start token, match[2]-end token\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3322c73b-48b5-4f59-8e87-7c84c2cf01ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "(451313080118390996, 50, 52) King advanced\n",
      "(451313080118390996, 90, 92) King participated\n",
      "(451313080118390996, 114, 116) King led\n",
      "(451313080118390996, 168, 170) King helped\n",
      "(451313080118390996, 248, 253) Director J. Edgar Hoover considered\n",
      "(451313080118390996, 323, 325) King won\n",
      "(451313080118390996, 486, 489) United States beginning\n"
     ]
    }
   ],
   "source": [
    "#every time it's after a verb\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "#all part of speech occurences of proper noun, + is one or more times, every time it's after a verb\n",
    "pattern = [{\"POS\":\"PROPN\", \"OP\":\"+\"},{\"POS\":\"VERB\"}]\n",
    "# only looks for longest token to give back\n",
    "matcher.add(\"PROPER_NOUN\", [pattern], greedy=\"LONGEST\")\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "#sort our matches - sort it by first index (start token)\n",
    "matches.sort(key= lambda x: x[1])\n",
    "# how many matches were found\n",
    "print(len(matches))\n",
    "#match[1]-start token, match[2]-end token\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6f08c24c-1c9f-4d93-8954-af464602bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"alice.json\", \"r\") as f:\n",
    "    data= json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ec5b92a9-b45f-4061-9913-b9445c8abe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "# first sentence from first chapter\n",
    "text= data[0][2][0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fdfaf46c-32fd-45f8-854c-c17af7ea4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaner text- standardize the text\n",
    "text = text.replace(\"`\",\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9bc02731-f987-4ee2-8290-8ceb7847a191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\yarde\\AppData\\Local\\Temp\\ipykernel_15656\\2513981340.py:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"label\": \"PHONE_NUMBER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"((\\d){5})\"}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5555555 PHONE_NUMBER\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "# * - zero or more times, \n",
    "pattern = [{\"ORTH\":\"'\"},\n",
    "           {\"IS_ALPHA\":True, \"OP\":\"+\"},\n",
    "           {\"IS_PUNC\": True, \"OP\":\"*\"},\n",
    "           {\"ORTH\":\"'\"}\n",
    "          ]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key= lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0cf90-d7f1-434e-918b-2f0f2b2dba0a",
   "metadata": {},
   "source": [
    "Now need to match who is the speaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "afcf2d4e-9738-474a-a996-743c08de8c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "speak_lemmas= [\"think\",\"say\"]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# next token needs to be a verb with lemmatized form that is contained in the speak_lemmas\n",
    "pattern = [{\"ORTH\":\"'\"},\n",
    "           {\"IS_ALPHA\":True, \"OP\":\"+\"},\n",
    "           {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "           {\"ORTH\":\"'\"},\n",
    "           {\"POS\":\"VERB\",\"LEMMA\":{\"IN\":speak_lemmas}},\n",
    "           {\"POS\":\"PROPN\", \"OP\":\"+\"},\n",
    "           {\"ORTH\":\"'\"},\n",
    "           {\"IS_ALPHA\":True, \"OP\":\"+\"},\n",
    "           {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "           {\"ORTH\":\"'\"}\n",
    "          ]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key= lambda x: x[1])\n",
    "print(len(matches))\n",
    "for match in matches[:10]:\n",
    "    print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3b5cf2d8-dc62-4893-a067-f82acd77759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
     ]
    }
   ],
   "source": [
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\",\"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key= lambda x: x[1])\n",
    "    for match in matches[:10]:\n",
    "        print(match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e744e-3534-48dc-9d8d-351cdd031ec6",
   "metadata": {},
   "source": [
    "singular and not multi patterns so we only get one result that fits it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "83d49113-3ac3-4b03-aa9a-6440507d9810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(3232560085755078826, 47, 67) 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 0, 6) 'Well!' thought Alice\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "(3232560085755078826, 57, 68) 'which certainly was not here before,' said Alice\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Here we add more patterns\n",
    "speak_lemmas = [\"think\", \"say\"]\n",
    "text = data[0][2][0].replace( \"`\", \"'\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "pattern2 = [{'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}, {\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "pattern3 = [{\"POS\": \"PROPN\", \"OP\": \"+\"},{\"POS\": \"VERB\", \"LEMMA\": {\"IN\": speak_lemmas}}, {'ORTH': \"'\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': \"'\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern1, pattern2, pattern3], greedy='LONGEST')\n",
    "for text in data[0][2]:\n",
    "    text = text.replace(\"`\", \"'\")\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches.sort(key = lambda x: x[1])\n",
    "    print (len(matches))\n",
    "    for match in matches[:10]:\n",
    "        print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9f2a6-7887-40ef-b253-6612621fcff6",
   "metadata": {},
   "source": [
    "### Custom Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b68d9c-126c-438e-b2f2-1f3c7d68285d",
   "metadata": {},
   "source": [
    "something that changes the doc object along the way in the pipeline\n",
    "\n",
    "Can change different entities to have different labels and remove things and print like to tell model to never give anything as GPE, GPE should be LOC (location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b34ead61-ba85-40dd-b676-e5765c45d365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Britain GPE\n",
      "Mary PERSON\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Britain is a place. Mary is a doctor\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "63eaed56-171a-4e14-9be3-bbd51afdf2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "#give it a name I want for it -  removes all gpe\n",
    "@Language.component(\"remove_gpe\")\n",
    "def remove_gpe(doc):\n",
    "    #change from generator to a list\n",
    "    original_ents= list(doc.ents)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\":\n",
    "            original_ents.remove(ent)\n",
    "    #convert back from a list\n",
    "    doc.ents = original_ents\n",
    "    return (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "fb81fe4e-0d63-48db-a5c6-60451001e7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'remove_gpe': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': [],\n",
       "  'remove_gpe': []},\n",
       " 'attrs': {'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []}}}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"remove_gpe\")\n",
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "da408069-8645-40bb-91fb-4190aacc4c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary PERSON\n"
     ]
    }
   ],
   "source": [
    "#check that gpe is removed\n",
    "doc = nlp(\"Britain is a place. Mary is a doctor\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95f760-d8c7-4119-9d43-35b371b48b36",
   "metadata": {},
   "source": [
    "Go to the disk and be saved with everything:\n",
    "\n",
    "nlp.to_disk(\"new_en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6094942-448e-46ad-91cb-488fb8876586",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f4893b-d001-4ae1-9988-36ba8ced6892",
   "metadata": {},
   "source": [
    "pattern matching only works in Regex for single tokens and not multi word token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "766f0c85-8750-4029-aae1-19892b49d865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\yarde\\AppData\\Local\\Temp\\ipykernel_15656\\2513981340.py:15: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"label\": \"PHONE_NUMBER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"((\\d){5})\"}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5555555 PHONE_NUMBER\n"
     ]
    }
   ],
   "source": [
    "#Import the requisite library\n",
    "import spacy\n",
    "\n",
    "#Sample text\n",
    "text = \"This is a sample number 5555555.\"\n",
    "#Build upon the spaCy Small Model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "#Create the Ruler and Add it\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "#List of Entities and Patterns (source: https://spacy.io/usage/rule-based-matching)\n",
    "patterns = [\n",
    "                {\n",
    "                    \"label\": \"PHONE_NUMBER\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"((\\d){5})\"}}\n",
    "                                                        ]\n",
    "                }\n",
    "            ]\n",
    "#add patterns to ruler\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "\n",
    "#create the doc\n",
    "doc = nlp(text)\n",
    "\n",
    "#extract entities\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ef8650-92c5-47a2-98ef-4519f04d4d66",
   "metadata": {},
   "source": [
    "#### Regex - Multi Word Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "006de25d-8845-4bd3-bd2d-73223b37e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"Paul Newman was an American actor, but Paul Hollywood is a British TV Host. The name Paul is quite common.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "b5c37eef-2f7b-4339-a900-91ca2a006cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Paul Newman'>\n",
      "<re.Match object; span=(39, 53), match='Paul Hollywood'>\n"
     ]
    }
   ],
   "source": [
    "# grab Paul with capital letter after and anything until the word break\n",
    "pattern = r\"Paul [A-Z]\\w+\"\n",
    "matches = re.finditer(pattern, text)\n",
    "for match in matches:\n",
    "    print(match)\n",
    "# span is the start and end character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1297d15b-4e38-4de0-b96c-25e6cf102d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "14afe2ba-154d-4992-ba8d-64e2f610a1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman\n",
      "Paul Hollywood\n",
      "[(0, 2, 'Paul Newman'), (8, 10, 'Paul Hollywood')]\n",
      "Paul Newman PERSON\n",
      "Paul Hollywood PERSON\n"
     ]
    }
   ],
   "source": [
    "#create blank spacy pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "doc = nlp(text)\n",
    "original_ents = list(doc.ents)\n",
    "#mwt- multi word tiken entity\n",
    "mwt_ents= []\n",
    "# look at doc container as raw text\n",
    "for match in re.finditer(pattern, doc.text):\n",
    "    start, end= match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    print(span)\n",
    "    if span is not None:\n",
    "        mwt_ents.append((span.start, span.end, span.text))\n",
    "#numbers are the token not characters\n",
    "print(mwt_ents)\n",
    "for ent in mwt_ents:\n",
    "    start, end, name = ent\n",
    "    per_ent = Span(doc, start, end, label=\"PERSON\")\n",
    "    original_ents.append(per_ent)\n",
    "doc.ents = original_ents\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985c8f9c-42e5-4a77-aded-ec482e4f23a1",
   "metadata": {},
   "source": [
    "Make this code a custom entity ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "8775e105-5cc0-4585-82dc-5ca9ce5da638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"paul_ner\")\n",
    "def paul_ner(doc):\n",
    "    pattern = r\"Paul [A-Z]\\w+\"\n",
    "    #create blank spacy pipeline\n",
    "    original_ents = list(doc.ents)\n",
    "    mwt_ents= []\n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end= match.span()\n",
    "        span = doc.char_span(start, end)\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, span.text))\n",
    "    for ent in mwt_ents:\n",
    "        start, end, name = ent\n",
    "        per_ent = Span(doc, start, end, label=\"PERSON\")\n",
    "        original_ents.append(per_ent)\n",
    "    doc.ents = original_ents\n",
    "    return (doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f7937243-5e71-46ef-a8fa-3aaa27a6cc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.paul_ner(doc)>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2 = spacy.blank('en')\n",
    "nlp2.add_pipe(\"paul_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b0d34b0c-826b-4492-a5e7-e3db9caf79ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Paul Newman, Paul Hollywood)\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp2(text)\n",
    "print(doc2.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "0d4fd734-1c46-498d-b67c-a5a5188e2e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.language import Language\n",
    "from spacy.util import filter_spans\n",
    "\n",
    "@Language.component(\"cinema_ner\")\n",
    "def cinema_ner(doc):\n",
    "    pattern = r\"Hollywood\"\n",
    "    #create blank spacy pipeline\n",
    "    original_ents = list(doc.ents)\n",
    "    mwt_ents= []\n",
    "    for match in re.finditer(pattern, doc.text):\n",
    "        start, end= match.span()\n",
    "        span = doc.char_span(start, end)\n",
    "        if span is not None:\n",
    "            mwt_ents.append((span.start, span.end, span.text))\n",
    "    for ent in mwt_ents:\n",
    "        start, end, name = ent\n",
    "        per_ent = Span(doc, start, end, label=\"CINEMA\")\n",
    "        original_ents.append(per_ent)\n",
    "    filtered = filter_spans(original_ents)\n",
    "    doc.ents = filtered\n",
    "    return (doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfba68c7-8475-481d-af60-33793e0c13fb",
   "metadata": {},
   "source": [
    "filter_spans goes through and see all start and end in entities and if there's an overlap there's priority for the longer token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "e208b81a-8918-46a6-beb1-6beff150ea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.cinema_ner(doc)>"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp3 = spacy.load('en_core_web_sm')\n",
    "nlp3.add_pipe(\"cinema_ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fac05c7f-d78c-40e4-99ac-ec4c3fdb1ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Newman PERSON\n",
      "American NORP\n",
      "Paul Hollywood PERSON\n",
      "British NORP\n",
      "Paul PERSON\n"
     ]
    }
   ],
   "source": [
    "doc3= nlp3(text)\n",
    "for ent in doc3.ents:\n",
    "    print (ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b15347-ef19-42c6-8997-10639b362ff6",
   "metadata": {},
   "source": [
    "## Applied SpaCy Financial NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "2c5ceae8-6893-47ef-8912-918e75581def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "11cf44f7-d5c4-4e6b-96fe-68a8381962c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Industry</th>\n",
       "      <th>MarketCap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Agilent Technologies</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>53.65B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>Alcoa</td>\n",
       "      <td>Metals &amp; Mining</td>\n",
       "      <td>9.25B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>Ares Acquisition</td>\n",
       "      <td>Shell Companies</td>\n",
       "      <td>1.22B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACG</td>\n",
       "      <td>ATA Creativity Global</td>\n",
       "      <td>Diversified Consumer Services</td>\n",
       "      <td>90.35M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AADI</td>\n",
       "      <td>Aadi Bioscience</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>104.85M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>ZWRK</td>\n",
       "      <td>Z-Work Acquisition</td>\n",
       "      <td>Shell Companies</td>\n",
       "      <td>278.88M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>ZY</td>\n",
       "      <td>Zymergen</td>\n",
       "      <td>Chemicals</td>\n",
       "      <td>1.31B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>Zymeworks</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>1.50B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5877</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>Zynerba Pharmaceuticals</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>184.39M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>ZYXI</td>\n",
       "      <td>Zynex</td>\n",
       "      <td>Health Care Equipment &amp; Supplies</td>\n",
       "      <td>438.33M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5879 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol              CompanyName                          Industry  \\\n",
       "0         A     Agilent Technologies    Life Sciences Tools & Services   \n",
       "1        AA                    Alcoa                   Metals & Mining   \n",
       "2       AAC         Ares Acquisition                   Shell Companies   \n",
       "3      AACG    ATA Creativity Global     Diversified Consumer Services   \n",
       "4      AADI          Aadi Bioscience                   Pharmaceuticals   \n",
       "...     ...                      ...                               ...   \n",
       "5874   ZWRK       Z-Work Acquisition                   Shell Companies   \n",
       "5875     ZY                 Zymergen                         Chemicals   \n",
       "5876   ZYME                Zymeworks                     Biotechnology   \n",
       "5877   ZYNE  Zynerba Pharmaceuticals                   Pharmaceuticals   \n",
       "5878   ZYXI                    Zynex  Health Care Equipment & Supplies   \n",
       "\n",
       "     MarketCap  \n",
       "0       53.65B  \n",
       "1        9.25B  \n",
       "2        1.22B  \n",
       "3       90.35M  \n",
       "4      104.85M  \n",
       "...        ...  \n",
       "5874   278.88M  \n",
       "5875     1.31B  \n",
       "5876     1.50B  \n",
       "5877   184.39M  \n",
       "5878   438.33M  \n",
       "\n",
       "[5879 rows x 4 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"stocks.tsv\", sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "2f43b33c-6d09-4eee-a22b-93b07ba25c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AA', 'AAC', 'AACG', 'AADI', 'AAIC', 'AAL', 'AAMC', 'AAME', 'AAN']\n"
     ]
    }
   ],
   "source": [
    "symbols = df.Symbol.tolist()\n",
    "companies = df.CompanyName.tolist()\n",
    "print(symbols[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "19ea77ba-b312-4841-a079-9729e0d44899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IndexName</th>\n",
       "      <th>IndexSymbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dow Jones Industrial Average</td>\n",
       "      <td>DJIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dow Jones Transportation Average</td>\n",
       "      <td>DJT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dow Jones Utility Average Index</td>\n",
       "      <td>DJU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NASDAQ 100 Index (NASDAQ Calculation)</td>\n",
       "      <td>NDX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASDAQ Composite Index</td>\n",
       "      <td>COMP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NYSE Composite Index</td>\n",
       "      <td>NYA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>S&amp;P 500 Index</td>\n",
       "      <td>SPX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>S&amp;P 400 Mid Cap Index</td>\n",
       "      <td>MID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S&amp;P 100 Index</td>\n",
       "      <td>OEX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NASDAQ Computer Index</td>\n",
       "      <td>IXCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PHLX Semiconductor Index</td>\n",
       "      <td>SOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHLX Gold/Silver Index</td>\n",
       "      <td>XAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NYSE Arca Oil Index</td>\n",
       "      <td>XOI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Russell 2000 Index</td>\n",
       "      <td>RUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                IndexName IndexSymbol\n",
       "0            Dow Jones Industrial Average        DJIA\n",
       "1        Dow Jones Transportation Average         DJT\n",
       "2         Dow Jones Utility Average Index         DJU\n",
       "3   NASDAQ 100 Index (NASDAQ Calculation)         NDX\n",
       "4                  NASDAQ Composite Index        COMP\n",
       "5                    NYSE Composite Index         NYA\n",
       "6                           S&P 500 Index        SPX \n",
       "7                   S&P 400 Mid Cap Index         MID\n",
       "8                           S&P 100 Index         OEX\n",
       "9                   NASDAQ Computer Index        IXCO\n",
       "10               PHLX Semiconductor Index         SOX\n",
       "11                 PHLX Gold/Silver Index         XAU\n",
       "12                    NYSE Arca Oil Index         XOI\n",
       "13                     Russell 2000 Index         RUT"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"indexes.tsv\", sep=\"\\t\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "8d8f2c49-c984-4179-a9c4-0133fb1c2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df2.IndexName.tolist()\n",
    "index_symbols = df2.IndexSymbol.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "b889626d-d788-4a5a-bea8-3d8bce1d346f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BloombergExchangeCode</th>\n",
       "      <th>BloombergCompositeCode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Description</th>\n",
       "      <th>ISOMIC</th>\n",
       "      <th>Google Prefix</th>\n",
       "      <th>EODcode</th>\n",
       "      <th>NumStocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF</td>\n",
       "      <td>AR</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Bolsa de Comercio de Buenos Aires</td>\n",
       "      <td>XBUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BA</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AO</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>National Stock Exchange of Australia</td>\n",
       "      <td>XNEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT</td>\n",
       "      <td>AU</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Asx - All Markets</td>\n",
       "      <td>XASX</td>\n",
       "      <td>ASX</td>\n",
       "      <td>AU</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Wiener Boerse Ag</td>\n",
       "      <td>XWBO</td>\n",
       "      <td>VIE</td>\n",
       "      <td>VI</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>Bahrain Bourse</td>\n",
       "      <td>XBAH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>UR</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>NASDAQ Capital Market</td>\n",
       "      <td>XNCM</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>US</td>\n",
       "      <td>2,209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UV</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>OTC markets</td>\n",
       "      <td>OOTC</td>\n",
       "      <td>OTCMKTS</td>\n",
       "      <td>US</td>\n",
       "      <td>2,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UW</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>NASDAQ Global Select</td>\n",
       "      <td>XNGS</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>US</td>\n",
       "      <td>1,768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>VH</td>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Hanoi Stock Exchange</td>\n",
       "      <td>HSTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>VM</td>\n",
       "      <td>VN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Hochiminh Stock Exchange</td>\n",
       "      <td>XSTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BloombergExchangeCode BloombergCompositeCode    Country  \\\n",
       "0                      AF                     AR  Argentina   \n",
       "1                      AO                     AU  Australia   \n",
       "2                      AT                     AU  Australia   \n",
       "3                      AV                    NaN    Austria   \n",
       "4                      BI                    NaN    Bahrain   \n",
       "..                    ...                    ...        ...   \n",
       "97                     UR                     US        USA   \n",
       "98                     UV                     US        USA   \n",
       "99                     UW                     US        USA   \n",
       "100                    VH                     VN    Vietnam   \n",
       "101                    VM                     VN    Vietnam   \n",
       "\n",
       "                              Description ISOMIC Google Prefix EODcode  \\\n",
       "0       Bolsa de Comercio de Buenos Aires   XBUE           NaN      BA   \n",
       "1    National Stock Exchange of Australia   XNEC           NaN     NaN   \n",
       "2                       Asx - All Markets   XASX           ASX      AU   \n",
       "3                        Wiener Boerse Ag   XWBO           VIE      VI   \n",
       "4                          Bahrain Bourse   XBAH           NaN     NaN   \n",
       "..                                    ...    ...           ...     ...   \n",
       "97                  NASDAQ Capital Market   XNCM        NASDAQ      US   \n",
       "98                            OTC markets   OOTC       OTCMKTS      US   \n",
       "99                   NASDAQ Global Select   XNGS        NASDAQ      US   \n",
       "100                  Hanoi Stock Exchange   HSTC           NaN     NaN   \n",
       "101              Hochiminh Stock Exchange   XSTC           NaN      VN   \n",
       "\n",
       "    NumStocks  \n",
       "0          12  \n",
       "1           1  \n",
       "2         875  \n",
       "3          38  \n",
       "4           4  \n",
       "..        ...  \n",
       "97      2,209  \n",
       "98      2,433  \n",
       "99      1,768  \n",
       "100         4  \n",
       "101        40  \n",
       "\n",
       "[102 rows x 8 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"stock_exchanges.tsv\", sep=\"\\t\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "cb14ad63-34b8-4d5a-bba7-3ad1ff3d7312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XBUE', 'XNEC', 'XASX', 'XWBO', 'XBAH', 'XDHA', 'XBRU', 'BVMF', 'XCNQ', 'XTSE']\n"
     ]
    }
   ],
   "source": [
    "exchanges = df3.ISOMIC.tolist() + df3['Google Prefix'].tolist()+df3.Description.tolist()\n",
    "print(exchanges[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "abe78cf3-927e-4d83-b90e-e1f198ef2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't want two to be included\n",
    "stops = ['two']\n",
    "nlp = spacy.blank('en')\n",
    "ruler = nlp.add_pipe('entity_ruler')\n",
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "patterns = []\n",
    "for symbol in symbols:\n",
    "    patterns.append({\"label\":\"STOCK\", \"pattern\":symbol})\n",
    "    for l in letters:\n",
    "        patterns.append({\"label\": \"STOCK\", \"pattern\": symbol+f\".{l}\"})\n",
    "for company in companies:\n",
    "    if company not in stops:\n",
    "        patterns.append({\"label\":\"COMPANY\", \"pattern\":company})\n",
    "for index in indexes:\n",
    "    patterns.append({\"label\":\"INDEX\", \"pattern\":index})\n",
    "    words = index.split()\n",
    "    patterns.append({\"label\":\"INDEX\", \"pattern\":\" \".join(words[:2])})\n",
    "for index in index_symbols:\n",
    "    patterns.append({\"label\":\"INDEX\", \"pattern\":index})\n",
    "for e in exchanges:\n",
    "    patterns.append({\"label\":\"STOCK_EXCHANGE\", \"pattern\":e})\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "bc4a2da9-0ad8-4d7c-b031-48bb7864e127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple COMPANY\n",
      "Apple COMPANY\n",
      "AAPL.O STOCK\n",
      "Apple COMPANY\n",
      "Nasdaq COMPANY\n",
      "S&P 500 INDEX\n",
      "S&P 500 INDEX\n",
      "ET STOCK\n",
      "Dow Jones Industrial Average INDEX\n",
      "S&P 500 INDEX\n",
      "Nasdaq COMPANY\n",
      "S&P 500 INDEX\n",
      "JD.com COMPANY\n",
      "TME.N STOCK\n",
      "NIO.N STOCK\n",
      "Kroger COMPANY\n",
      "KR.N STOCK\n",
      "NYSE STOCK_EXCHANGE\n",
      "Nasdaq COMPANY\n",
      "Nasdaq COMPANY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "42cc3f31-1ef9-41d5-94f8-3d8df0f01341",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "Sept 10 (Reuters) - Wall Street's main indexes were subdued on Friday as signs of higher inflation and a drop in Apple shares following an unfavorable court ruling offset expectations of an easing in U.S.-China tensions.\n",
    "\n",
    "Data earlier in the day showed U.S. producer prices rose solidly in August, leading to the biggest annual gain in nearly 11 years and indicating that high inflation was likely to persist as the pandemic pressures supply chains. read more .\n",
    "\n",
    "\"Today's data on wholesale prices should be eye-opening for the Federal Reserve, as inflation pressures still don't appear to be easing and will likely continue to be felt by the consumer in the coming months,\" said Charlie Ripley, senior investment strategist for Allianz Investment Management.\n",
    "\n",
    "Apple Inc (AAPL.O) fell 2.7% following a U.S. court ruling in \"Fortnite\" creator Epic Games' antitrust lawsuit that stroke down some of the iPhone maker's restrictions on how developers can collect payments in apps.\n",
    "\n",
    "\n",
    "Sponsored by Advertising Partner\n",
    "Sponsored Video\n",
    "Watch to learn more\n",
    "Report ad\n",
    "Apple shares were set for their worst single-day fall since May this year, weighing on the Nasdaq (.IXIC) and the S&P 500 technology sub-index (.SPLRCT), which fell 0.1%.\n",
    "\n",
    "Sentiment also took a hit from Cleveland Federal Reserve Bank President Loretta Mester's comments that she would still like the central bank to begin tapering asset purchases this year despite the weak August jobs report. read more\n",
    "\n",
    "Investors have paid keen attention to the labor market and data hinting towards higher inflation recently for hints on a timeline for the Federal Reserve to begin tapering its massive bond-buying program.\n",
    "\n",
    "The S&P 500 has risen around 19% so far this year on support from dovish central bank policies and re-opening optimism, but concerns over rising coronavirus infections and accelerating inflation have lately stalled its advance.\n",
    "\n",
    "\n",
    "Report ad\n",
    "The three main U.S. indexes got some support on Friday from news of a phone call between U.S. President Joe Biden and Chinese leader Xi Jinping that was taken as a positive sign which could bring a thaw in ties between the world's two most important trading partners.\n",
    "\n",
    "At 1:01 p.m. ET, the Dow Jones Industrial Average (.DJI) was up 12.24 points, or 0.04%, at 34,891.62, the S&P 500 (.SPX) was up 2.83 points, or 0.06%, at 4,496.11, and the Nasdaq Composite (.IXIC) was up 12.85 points, or 0.08%, at 15,261.11.\n",
    "\n",
    "Six of the eleven S&P 500 sub-indexes gained, with energy (.SPNY), materials (.SPLRCM) and consumer discretionary stocks (.SPLRCD) rising the most.\n",
    "\n",
    "U.S.-listed Chinese e-commerce companies Alibaba and JD.com , music streaming company Tencent Music (TME.N) and electric car maker Nio Inc (NIO.N) all gained between 0.7% and 1.4%\n",
    "\n",
    "\n",
    "Report ad\n",
    "Grocer Kroger Co (KR.N) dropped 7.1% after it said global supply chain disruptions, freight costs, discounts and wastage would hit its profit margins.\n",
    "\n",
    "Advancing issues outnumbered decliners by a 1.12-to-1 ratio on the NYSE and by a 1.02-to-1 ratio on the Nasdaq.\n",
    "\n",
    "The S&P index recorded 14 new 52-week highs and three new lows, while the Nasdaq recorded 49 new highs and 38 new lows.\n",
    "\n",
    "'''\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ea4c1686-22df-4696-ad52-4de26c467911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple COMPANY\n",
      "Apple COMPANY\n",
      "AAPL.O STOCK\n",
      "Apple COMPANY\n",
      "Nasdaq COMPANY\n",
      "S&P 500 INDEX\n",
      "S&P 500 INDEX\n",
      "ET STOCK\n",
      "Dow Jones Industrial Average INDEX\n",
      "S&P 500 INDEX\n",
      "Nasdaq COMPANY\n",
      "S&P 500 INDEX\n",
      "JD.com COMPANY\n",
      "TME.N STOCK\n",
      "NIO.N STOCK\n",
      "Kroger COMPANY\n",
      "KR.N STOCK\n",
      "NYSE STOCK_EXCHANGE\n",
      "Nasdaq COMPANY\n",
      "Nasdaq COMPANY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "99a50d13-3612-4018-bd06-81ddac87344b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Sept 10 (Reuters) - Wall Street's main indexes were subdued on Friday as signs of higher inflation and a drop in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " shares following an unfavorable court ruling offset expectations of an easing in U.S.-China tensions.<br><br>Data earlier in the day showed U.S. producer prices rose solidly in August, leading to the biggest annual gain in nearly 11 years and indicating that high inflation was likely to persist as the pandemic pressures supply chains. read more .<br><br>&quot;Today's data on wholesale prices should be eye-opening for the Federal Reserve, as inflation pressures still don't appear to be easing and will likely continue to be felt by the consumer in the coming months,&quot; said Charlie Ripley, senior investment strategist for Allianz Investment Management.<br><br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " Inc (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AAPL.O\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
       "</mark>\n",
       ") fell 2.7% following a U.S. court ruling in &quot;Fortnite&quot; creator Epic Games' antitrust lawsuit that stroke down some of the iPhone maker's restrictions on how developers can collect payments in apps.<br><br><br>Sponsored by Advertising Partner<br>Sponsored Video<br>Watch to learn more<br>Report ad<br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " shares were set for their worst single-day fall since May this year, weighing on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nasdaq\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " (.IXIC) and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    S&amp;P 500\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INDEX</span>\n",
       "</mark>\n",
       " technology sub-index (.SPLRCT), which fell 0.1%.<br><br>Sentiment also took a hit from Cleveland Federal Reserve Bank President Loretta Mester's comments that she would still like the central bank to begin tapering asset purchases this year despite the weak August jobs report. read more<br><br>Investors have paid keen attention to the labor market and data hinting towards higher inflation recently for hints on a timeline for the Federal Reserve to begin tapering its massive bond-buying program.<br><br>The \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    S&amp;P 500\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INDEX</span>\n",
       "</mark>\n",
       " has risen around 19% so far this year on support from dovish central bank policies and re-opening optimism, but concerns over rising coronavirus infections and accelerating inflation have lately stalled its advance.<br><br><br>Report ad<br>The three main U.S. indexes got some support on Friday from news of a phone call between U.S. President Joe Biden and Chinese leader Xi Jinping that was taken as a positive sign which could bring a thaw in ties between the world's two most important trading partners.<br><br>At 1:01 p.m. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ET\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
       "</mark>\n",
       ", the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dow Jones Industrial Average\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INDEX</span>\n",
       "</mark>\n",
       " (.DJI) was up 12.24 points, or 0.04%, at 34,891.62, the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    S&amp;P 500\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INDEX</span>\n",
       "</mark>\n",
       " (.SPX) was up 2.83 points, or 0.06%, at 4,496.11, and the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nasdaq\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " Composite (.IXIC) was up 12.85 points, or 0.08%, at 15,261.11.<br><br>Six of the eleven \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    S&amp;P 500\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INDEX</span>\n",
       "</mark>\n",
       " sub-indexes gained, with energy (.SPNY), materials (.SPLRCM) and consumer discretionary stocks (.SPLRCD) rising the most.<br><br>U.S.-listed Chinese e-commerce companies Alibaba and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JD.com\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " , music streaming company Tencent Music (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TME.N\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
       "</mark>\n",
       ") and electric car maker Nio Inc (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NIO.N\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
       "</mark>\n",
       ") all gained between 0.7% and 1.4%<br><br><br>Report ad<br>Grocer \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Kroger\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " Co (\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    KR.N\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK</span>\n",
       "</mark>\n",
       ") dropped 7.1% after it said global supply chain disruptions, freight costs, discounts and wastage would hit its profit margins.<br><br>Advancing issues outnumbered decliners by a 1.12-to-1 ratio on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    NYSE\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">STOCK_EXCHANGE</span>\n",
       "</mark>\n",
       " and by a 1.02-to-1 ratio on the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nasdaq\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       ".<br><br>The S&amp;P index recorded 14 new 52-week highs and three new lows, while the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nasdaq\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">COMPANY</span>\n",
       "</mark>\n",
       " recorded 49 new highs and 38 new lows.<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
